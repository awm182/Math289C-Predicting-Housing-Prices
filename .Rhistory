#create table w/ proper labels
palindromes3 <- c('0-1','2', '3', '4', '5','6', '7+')
observed3 <-c(k75.tab[,1])
expected3 <-c(k75.tab[,2])
k75.fulltab <-data.frame(palindromes3, observed3, expected3)
#calculate chi-square test statistic
k75.stats <- sum((k75.tab[,2] - k75.tab[,1])^2/k75.tab[,2])
pchisq(k75.stats, 4 - 2, lower.tail=FALSE)
#graphically check data distribution to Poisson
#hist of counts
hist(counts3, breaks = 15, col = rgb(1,0,0,0.5), probability = TRUE, xlab = "number of points inside an interval", ylim = c(0,0.3))
lines(density(counts3, adjust = 2), col = rgb(1,0,0,0.5))
#compare w/ Poisson distribution
Pois <- rpois(sum(counts3), lambda = mean(counts3))
hist(Pois, breaks = 15, col = rgb(0,0,1,0.5), probability = TRUE, add = TRUE)
lines(density(Pois, adjust = 2), col = rgb(0,0,1,0.5))
legend(x = 10, y = 0.15, legend = c("sample", "Poisson"), lty = c(1,1), col = c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
#check residual plot
lambda3 <-mean(counts3)
Residuals <- (counts3 - lambda3) / sqrt(lambda3)
plot(Residuals, type = 'h', ylab = "standardized residuals", xlab = "interval index")
#check for normality using Shapiro-Wilks test
shapiro.test(counts)
shapiro.test(counts2)
shapiro.test(counts3)
#check diffs in variance
var.test(counts, counts2)
var.test(counts, counts3)
var.test(counts2, counts3)
t.test(counts, counts2, paired = FALSE, var.equal = TRUE)
t.test(counts, counts3, paired = FALSE, var.equal = TRUE)
t.test(counts2, counts3, paired = FALSE, var.equal = TRUE)
pois1 <-rpois(sum(counts), lambda = mean(counts))
pois2 <-rpois(sum(counts2), lambda = mean(counts2))
pois3 <-rpois(sum(counts3), lambda = mean(counts3))
#compare variances
var.test(counts, pois1)
var.test(counts2, pois2)
var.test(counts3, pois3)
#t-test between the means
t.test(counts, pois1, paired = FALSE, var.equal = TRUE)
t.test(counts2, pois2, paired = FALSE, var.equal = TRUE)
t.test(counts3, pois3, paired = FALSE, var.equal = TRUE)
#K-S test to check is dists are significantly different
ks.test(counts, pois1)
ks.test(counts2, pois2)
ks.test(counts3, pois3)
#create table w/ proper labels
palindromes3 <- c('0-1','2', '3', '4', '5','6', '7+')
observed3 <-c(k75.tab[,1])
expected3 <-c(k75.tab[,2])
k75.fulltab <-data.frame(palindromes3, observed3, expected3)
#calculate chi-square test statistic
k75.stats <- sum((k75.tab[,2] - k75.tab[,1])^2/k75.tab[,2])
pchisq(k75.stats, 7 - 2, lower.tail=FALSE)
#create table w/ proper labels
palindromes3 <- c('0-1','2', '3', '4', '5','6', '7+')
observed3 <-c(k75.tab[,1])
expected3 <-c(k75.tab[,2])
k75.fulltab <-data.frame(palindromes3, observed3, expected3)
#calculate chi-square test statistic
k75.stats <- sum((k75.tab[,2] - k75.tab[,1])^2/k75.tab[,2])
pchisq(k75.stats, 7 - 2, lower.tail=FALSE)
#K-S test to check is dists are significantly different
ks.test(counts, pois1)
ks.test(counts2, pois2)
ks.test(counts3, pois3)
#make chisquare table for the counts
site <-data$location
chisqtable <- function(k, site, N) {
n <-length(site)
#estimate lambda
lambda.est <- n/k
#intervals already cut into counts
count.vector <-counts
count.range <- max(count.vector) - min(count.vector) + 1
#create contingency table
table <- matrix(rep(NA, count.range*3), count.range, 3)
for (i in 1:count.range){
offset <- min(count.vector) - 1
# first column = count level
table[i, 1] <- i + offset
# second column = observed count
table[i, 2] <- sum(count.vector == i + offset)
# third column = expected count
if ((i + offset == min(count.vector)) && (min(count.vector) != 0))
table[i, 3] <- ppois(i+offset, lambda.est)*k
else if (i + offset == max(count.vector))
table[i, 3] <- 1 - ppois(i + offset - 1, lambda.est)
else
table[i, 3] <- (ppois(i+offset, lambda.est) - ppois(i + offset - 1, lambda.est))*k
}
return (table)
}
k50.tabtemp <- chisqtable(k, site, N)
View(k50.tabtemp)
k50.tab <- matrix(rep(NA, 7*2), 7, 2)
k50.tab[1,] <- colSums(k50.tabtemp[1:4, 2:3])
k50.tab[2:6,] <- k50.tabtemp[5:9, 2:3]
k50.tab[7,] <- colSums(k50.tabtemp[10:17, 2:3])
#create table w/ proper labels
k50.row1 <- c('0-3','4','5','6','7','8','9+')
k50.row2<-c(k50.tab[,1])
k50.row3 <-c(k50.tab[,2])
k50.fulltab <-data.frame(k50.row1, k50.row2, k50.row3)
names(k50.fulltab)[1]<-paste("Palindrome Count")
names(k50.fulltab)[2]<-paste("Observed")
names(k50.fulltab)[3]<-paste("Expected")
#calculate chi-square test statistic
k50.stats <- sum((k50.tab[,2] - k50.tab[,1])^2/k50.tab[,2])
pchisq(k50.stats, 7 - 2, lower.tail=FALSE)
View(k50.tab)
k50.tab <- matrix(rep(NA, 7*2), 7, 2)
k50.tab[1,] <- colSums(k50.tabtemp[1:4, 2:3])
k50.tab[2:6,] <- k50.tabtemp[5:9, 2:3]
k50.tab[7,] <- colSums(k50.tabtemp[10:17, 2:3])
#create table w/ proper labels
k50.row1 <- c('0-3','4','5','6','7','8','9+')
k50.row2<-c(k50.tab[,1])
k50.row3 <-c(k50.tab[,2])
k50.fulltab <-data.frame(k50.row1, k50.row2, k50.row3)
names(k50.fulltab)[1]<-paste("Palindrome Count")
names(k50.fulltab)[2]<-paste("Observed")
names(k50.fulltab)[3]<-paste("Expected")
#calculate chi-square test statistic
k50.stats <- sum((k50.tab[,2] - k50.tab[,1])^2/k50.tab[,2])
pchisq(k50.stats, 7 - 2, lower.tail=FALSE)
View(k50.fulltab)
#create counts based on intervals
k <-50
N <-max(data$location)
tab <-table(cut(data$location, breaks=seq(1,N, length.out=k+1)))
counts <-as.vector(tab)
head(counts, N)
#create counts based on intervals
k <-51
N <-max(data$location)
tab <-table(cut(data$location, breaks=seq(1,N, length.out=k+1)))
counts <-as.vector(tab)
head(counts, N)
#create counts based on intervals
k <-50
N <-max(data$location)
tab <-table(cut(data$location, breaks=seq(1,N, length.out=k+1)))
counts <-as.vector(tab)
head(counts, N)
#create counts based on intervals
k <-51
N <-max(data$location)
tab <-table(cut(data$location, breaks=seq(1,N, length.out=k+1)))
counts <-as.vector(tab)
head(counts, N)
#create counts based on intervals
k <-50
N <-max(data$location)
tab <-table(cut(data$location, breaks=seq(1,N, length.out=k+1)))
counts <-as.vector(tab)
head(counts, N)
#make chisquare table for the counts
site <-data$location
chisqtable <- function(k, site, N) {
n <-length(site)
#estimate lambda
lambda.est <- n/k
#intervals already cut into counts
count.vector <-counts
count.range <- max(count.vector) - min(count.vector) + 1
#create contingency table
table <- matrix(rep(NA, count.range*3), count.range, 3)
for (i in 1:count.range){
offset <- min(count.vector) - 1
# first column = count level
table[i, 1] <- i + offset
# second column = observed count
table[i, 2] <- sum(count.vector == i + offset)
# third column = expected count
if ((i + offset == min(count.vector)) && (min(count.vector) != 0))
table[i, 3] <- ppois(i+offset, lambda.est)*k
else if (i + offset == max(count.vector))
table[i, 3] <- 1 - ppois(i + offset - 1, lambda.est)
else
table[i, 3] <- (ppois(i+offset, lambda.est) - ppois(i + offset - 1, lambda.est))*k
}
return (table)
}
k50.tabtemp <- chisqtable(k, site, N)
k50.tab <- matrix(rep(NA, 7*2), 7, 2)
k50.tab[1,] <- colSums(k50.tabtemp[1:4, 2:3])
k50.tab[2:6,] <- k50.tabtemp[5:9, 2:3]
k50.tab[7,] <- colSums(k50.tabtemp[10:17, 2:3])
#create table w/ proper labels
k50.row1 <- c('0-3','4','5','6','7','8','9+')
k50.row2<-c(k50.tab[,1])
k50.row3 <-c(k50.tab[,2])
k50.fulltab <-data.frame(k50.row1, k50.row2, k50.row3)
names(k50.fulltab)[1]<-paste("Palindrome Count")
names(k50.fulltab)[2]<-paste("Observed")
names(k50.fulltab)[3]<-paste("Expected")
#calculate chi-square test statistic
k50.stats <- sum((k50.tab[,2] - k50.tab[,1])^2/k50.tab[,2])
pchisq(k50.stats, 7 - 2, lower.tail=FALSE)
#create table w/ proper labels
palindromes3 <- c('0-1','2', '3', '4', '5','6', '7+')
observed3 <-c(k75.tab[,1])
expected3 <-c(k75.tab[,2])
k75.fulltab <-data.frame(palindromes3, observed3, expected3)
names(k75.fulltab)[1]<-paste("Palindrome Count")
names(k75.fulltab)[2]<-paste("Observed")
names(k75.fulltab)[3]<-paste("Expected")
#calculate chi-square test statistic
k75.stats <- sum((k75.tab[,2] - k75.tab[,1])^2/k75.tab[,2])
pchisq(k75.stats, 7 - 2, lower.tail=FALSE)
View(k75.fulltab)
View(k75.tabtemp)
#create table w/ proper labels
palindromes2 <- c('5-9','10-11', '12-13', '13+')
observed2 <-c(k25.tab[,1])
expected2 <-c(k25.tab[,2])
k25.fulltab <-data.frame(palindromes2, observed2, expected2)
names(k25.fulltab)[1]<-paste("Palindrome Count")
names(k25.fulltab)[2]<-paste("Observed")
names(k25.fulltab)[3]<-paste("Expected")
#calculate chi-square test statistic
k25.stats <- sum((k25.tab[,2] - k25.tab[,1])^2/k25.tab[,2])
pchisq(k25.stats, 4 - 2, lower.tail=FALSE)
#graphically check data distribution to Poisson
#hist of counts
hist(counts3, breaks = 15, col = rgb(1,0,0,0.5), probability = TRUE, xlab = "number of points inside an interval", ylim = c(0,0.3))
lines(density(counts3, adjust = 2), col = rgb(1,0,0,0.5))
#compare w/ Poisson distribution
Pois <- rpois(sum(counts3), lambda = mean(counts3))
hist(Pois, breaks = 15, col = rgb(0,0,1,0.5), probability = TRUE, add = TRUE)
lines(density(Pois, adjust = 2), col = rgb(0,0,1,0.5))
legend(x = 10, y = 0.15, legend = c("sample", "Poisson"), lty = c(1,1), col = c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
#graphically check data distribution to Poisson
#hist of counts
hist(counts3, breaks = 15, col = rgb(1,0,0,0.5), probability = TRUE, xlab = "number of points inside an interval", ylim = c(0,0.3))
lines(density(counts3, adjust = 2), col = rgb(1,0,0,0.5))
#compare w/ Poisson distribution
Pois <- rpois(sum(counts3), lambda = mean(counts3))
hist(Pois, breaks = 12, col = rgb(0,0,1,0.5), probability = TRUE, add = TRUE)
lines(density(Pois, adjust = 2), col = rgb(0,0,1,0.5))
legend(x = 10, y = 0.15, legend = c("sample", "Poisson"), lty = c(1,1), col = c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
#log transformation to better fit the model
log10(data)
#log transformation to better fit the model
log10(data)
plot(log10(data))
#log transformation to better fit the model
logtrans <-log10(data)
logtrans
data <-read.table("gauge.txt", header=TRUE)
head(data)
plot(data)
#test for linearity of ffit
lfit <-lm(gain~density, data=data)
plot(lfit)
#residuals
rfit <-resid(lfit)
#plot
plot(data$gain, rfit)
abline(0,0) #the horizon
#log transformation to better fit the model
logtrans <-log10(data)
#log transformation to better fit the model
logtrans <-log10(data)
#log transformation to better fit the model
logtrans <-log10(data)
logtrans
#log transformation to better fit the model
logtrans <-log10(data)
plot(logtrans)
#log transformation to better fit the model
fit <-lm(gain~log(density))
#log transformation to better fit the model
fit <-lm(gain~log(density), data=data)
#log transformation to better fit the model
fit <-lm(data$gain~log(data$density))
#log transformation to better fit the model
fit <-lm(density~log(gain),data=data)
#log transformation to better fit the model
fit <-lm(log(density)~log(gain),data=data)
data <-read.table("gauge.txt", header=TRUE)
head(data)
plot(data)
#test for linearity of ffit
lfit <-lm(gain~density, data=data)
plot(lfit)
#residuals
rfit <-resid(lfit)
#plot
plot(data$gain, rfit)
abline(0,0) #the horizon
#log transformation to better fit the model
fit <-lm(log(gain)~log(density),data=data)
summary(fit)
#log transformation to better fit the model
fit <-lm(log(gain)~log(density),data=data)
summary(fit)
plot(fit)
#log transformation to better fit the model
fit <-lm(log(gain)~log(density),data=data)
summary(fit)
plot(data$gain, fit)
#test for linearity of ffit
lfit <-lm(gain~density, data=data)
#residuals
rfit <-resid(lfit)
#plot
plot(data$gain, rfit)
abline(0,0) #the horizon
#log transformation to better fit the model
fit <-lm(log(gain)~log(density),data=data)
summary(fit)
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lm(gain~density), newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
data <-read.table("gauge.txt", header=TRUE)
head(data)
plot(data)
#test for linearity of ffit
lfit <-lm(gain~density, data=data)
#residuals
rfit <-resid(lfit)
#plot
plot(data$gain, rfit)
abline(0,0) #the horizon
#log transformation to better fit the model
fit <-lm(log(gain)~log(density),data=data)
summary(fit)
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain==38.6)
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
?(predict)
help("predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(density=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(density=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#test for linearity of ffit
lfit <-lm(density~gain, data=data)
#residuals
rfit <-resid(lfit)
#plot
plot(data$density, rfit)
abline(0,0) #the horizon
plot(data$gain, data$density)
#log transformation to better fit the model
fit <-lm(log(density)~log(gain),data=data)
summary(fit)
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(density=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#log transformation to better fit the model
fit <-lm(density~log(gain),data=data)
summary(fit)
#log transformation to better fit the model
fit <-lm(density~log(gain),data=data)
summary(fit)
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(fit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=log(38.6))
#predict model
predmod <-predict(fit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=log(426.7))
#predict model
predmod <-predict(fit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=log(38.6))
#predict model
predmod <-predict(fit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=log(38.6)
#predict model
predmod <-predict(fit, newdata, interval="predict")
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=log(38.6))
#predict model
predmod <-predict(fit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=426.7)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=426.7)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(lfit, newdata, interval="predict")
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=38.6)
#predict model
predmod <-predict(fit, newdata)
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=426.7)
#predict model
predmod <-predict(fit, newdata)
predmod
#predict at 95% interval
#set gain value to 38.6
newdata <-data.frame(gain=426.7)
#predict model
predmod <-predict(lfit, newdata)
predmod
plot(data$gain, data$density)
abline(density~gain, data=data)
plot(data$gain, data$density)
abline(gain~density, data=data)
plot(data$gain, data$density)
abline(data$density~data$gain)
plot(data$gain, data$density)
abline(data$gain~data$density)
#log transformation to better fit the model
fit <-lm(density~log(gain),data=data)
summary(fit)
plot(log(data$gain),log(data$density))
#log transformation to better fit the model
fit <-lm(density~log(gain),data=data)
summary(fit)
plot(log(data$gain),data$density)
getwd()
getwd()
setwd("Math189-Predicting-Housing-Prices/Math189-Predicting-Housing-Prices/")
data <-read.table("testReplaceMean.csv", sep=",", header=TRUE)
getwd()
setwd("Math189-Predicting-Housing-Prices/Math189-Predicting-Housing-Prices/")
data <-read.table("testReplaceMean.csv", sep=",", header=TRUE)
head(data)
data <-read.table("trainReplaceMean.csv", sep=",", header=TRUE)
head(data)
plot(data$SalePrice, data$LotArea)
plot(data$SalePrice~data$LotArea)
data <-read.table("trainReplaceMean.csv", sep=",", header=TRUE)
head(data)
plot(data$SalePrice~data$LotArea)
plot(data$SalePrice~data$LowQualFinSF)
plot(data$SalePrice~data$LotArea)
